{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scripts to setup the development environment\n",
        "\n",
        "Choose a GPU runtime (L4/T4/A100/H100). Do not choose CPU/TPU runtime."
      ],
      "metadata": {
        "id": "Ldub78mBVbq4"
      },
      "id": "Ldub78mBVbq4"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cd1C9uM-dO4l"
      },
      "id": "cd1C9uM-dO4l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b406cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48b406cd",
        "outputId": "1fe1f912-7170-4943-95b5-bf1b4b8a969c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /mnt\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive to the \"/mnt\" folder in the Colab virtual machine\n",
        "from google.colab import drive\n",
        "drive.mount(\"/mnt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fceb8df",
      "metadata": {
        "id": "6fceb8df",
        "outputId": "15d2e105-e84c-47cc-a8d2-450001799776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mnt/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# create folder and \"cd\" to the path\n",
        "!mkdir -p /mnt/MyDrive/\n",
        "%cd \"/mnt/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247bcbbc",
      "metadata": {
        "id": "247bcbbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77474265-ad7b-47bc-97e1-43eac773b193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transaxx'...\n",
            "remote: Enumerating objects: 199, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 199 (delta 36), reused 114 (delta 36), pack-reused 78 (from 1)\u001b[K\n",
            "Receiving objects: 100% (199/199), 407.41 KiB | 901.00 KiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ],
      "source": [
        "# clone Gihub repo\n",
        "!git clone https://github.com/changmg/transaxx.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40c8dd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40c8dd0",
        "outputId": "f011e0f3-5322-4ab9-86f4-bbff5d6f905b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mnt/MyDrive/transaxx\n"
          ]
        }
      ],
      "source": [
        "# \"cd\" to the repo folder\n",
        "%cd \"/mnt/MyDrive/transaxx\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install python package(s)\n",
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4ueXBX9TPxT",
        "outputId": "49170e4f-50dc-42b4-efea-62ff2ec484dd"
      },
      "id": "-4ueXBX9TPxT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/180.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6f0af6",
      "metadata": {
        "id": "3a6f0af6"
      },
      "source": [
        "# Model evaluation and re-training with TransAxx on CIFAR10 dataset\n",
        "\n",
        "In this notebook you can evaluate different approximate multipliers on various models.\n",
        "You can also retrain the model for further accuracy improvement\n",
        "\n",
        "**Note**:\n",
        "* Currently, the quantization bitwidth supported is 8bit and supported layers are Conv2d and Linear\n",
        "\n",
        "* Please make sure you have run the installation steps first\n",
        "\n",
        "* This example notebook approximates Conv2d layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31a01e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f31a01e0",
        "outputId": "800760c9-76ae-4391-d878-f2fd1d62876d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Compute Architecture: sm_89\n",
            "CUDA Compute Architecture: sm_89\n"
          ]
        }
      ],
      "source": [
        "from classification.utils import *\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3edbe30f",
      "metadata": {
        "id": "3edbe30f"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "Set your path for the CIFAR10 dataset\n",
        "\n",
        "'calib dataset' is created from a 10% sample of train data for calibration purposes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd00e88a-3fab-48de-acc5-3a4a7fc7c472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd00e88a-3fab-48de-acc5-3a4a7fc7c472",
        "outputId": "7fac011d-4434-4601-bb04-d3fb872ba659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "val_data, calib_data = cifar10_data_loader(data_path=\"./datasets/cifar10_data\", batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bae3e54",
      "metadata": {
        "id": "3bae3e54"
      },
      "source": [
        "## Select a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea9319f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ea9319f",
        "outputId": "3ec05d33-8772-4f0f-916d-a23998e4d4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:335: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/repvgg/cifar10_repvgg_a0-ef08a50e.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_repvgg_a0-ef08a50e.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.1M/30.1M [00:00<00:00, 37.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# an example repo with cifar10 models. you can use your own (ref: https://github.com/chenyaofo/pytorch-cifar-models)\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", 'cifar10_repvgg_a0', pretrained=True).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f2e8b9-0c1c-4a5e-b0f9-8c1c55d8dead",
      "metadata": {
        "id": "60f2e8b9-0c1c-4a5e-b0f9-8c1c55d8dead"
      },
      "source": [
        "## Optional: Evaluate default model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212cd8c3-cdd3-47af-b7dc-ea677f9df40a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "212cd8c3-cdd3-47af-b7dc-ea677f9df40a",
        "outputId": "8968784f-359d-46e0-df8c-faacc3446327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:02<00:00, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4874628289999805\n",
            "Accuracy of the network on the 10000 test images: 94.3209 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "top1 = evaluate_cifar10(model, val_data, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe4183a",
      "metadata": {
        "id": "efe4183a"
      },
      "source": [
        "## Initialize model with axx layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1064ebb6-2bdf-4523-981a-cab5dc3ae0ae",
      "metadata": {
        "id": "1064ebb6-2bdf-4523-981a-cab5dc3ae0ae"
      },
      "outputs": [],
      "source": [
        "# get conv2d layers to approximate\n",
        "conv2d_layers = [(name, module) for name, module in model.named_modules() if (isinstance(module, torch.nn.Conv2d) or isinstance(module, AdaptConv2D)) and (\"head\" not in name and \"reduction\" not in name)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce2db2d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce2db2d4",
        "outputId": "fc4dba38-8015-4acc-b13a-10b2a95a5c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(conv2d_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b65a94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b65a94",
        "outputId": "1bffe89a-5322-4de2-e22e-cad5fd61aa81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to compile cuda extensions:  142.7679636478424\n"
          ]
        }
      ],
      "source": [
        "# Initialize model with all required approximate multipliers for axx layers.\n",
        "# No explicit assignment needed; this step JIT compiles all upcoming multipliers\n",
        "\n",
        "axx_list = [{'axx_mult' : 'mul8s_acc', 'axx_power' : 1.0, 'quant_bits' : 8, 'fake_quant' : False}]*len(conv2d_layers)\n",
        "axx_list[3:4] = [{'axx_mult' : 'mul8s_1L2H', 'axx_power' : 0.7082, 'quant_bits' : 8, 'fake_quant' : False}] * 1\n",
        "\n",
        "start = time.time()\n",
        "replace_conv_layers(model,  AdaptConv2D, axx_list, 0, 0, layer_count=[0], returned_power = [0], initialize = True)\n",
        "print('Time to compile cuda extensions: ', time.time()-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512ada14",
      "metadata": {
        "id": "512ada14",
        "outputId": "bf172c3f-0291-4083-f06d-07daba7f5a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module TensorQuantizer is treated as a zero-op.\n",
            "Warning: module RepVGGBlock is treated as a zero-op.\n",
            "Warning: module RepVGG is treated as a zero-op.\n",
            "Computational complexity:  491.95 MMacs\n",
            "Number of parameters::  7.84 MParams\n"
          ]
        }
      ],
      "source": [
        "# measure flops of model and compute 'flops' in every layer\n",
        "\n",
        "import io\n",
        "from classification.ptflops import get_model_complexity_info\n",
        "from classification.ptflops.pytorch_ops import linear_flops_counter_hook\n",
        "from classification.ptflops.pytorch_ops import conv_flops_counter_hook\n",
        "\n",
        "#hook our custom axx_layers in the appropriate flop counters, i.e. AdaptConv2D : conv_flops_counter_hook\n",
        "with torch.cuda.device(0):\n",
        "    total_macs, total_params, layer_specs = get_model_complexity_info(model, (3, 32, 32),as_strings=False, print_per_layer_stat=True,\n",
        "                                                          custom_modules_hooks={AdaptConv2D : conv_flops_counter_hook},\n",
        "                                                          param_units='M', flops_units='MMac',\n",
        "                                                          verbose=True)\n",
        "\n",
        "print(f'Computational complexity:  {total_macs/1000000:.2f} MMacs')\n",
        "print(f'Number of parameters::  {total_params/1000000:.2f} MParams')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f4f461",
      "metadata": {
        "id": "52f4f461"
      },
      "source": [
        "## Run model calibration for quantization\n",
        "\n",
        "Calibrates the quantization parameters\n",
        "\n",
        "Need to re-run it each time the initial model changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e67ac6e",
      "metadata": {
        "id": "8e67ac6e",
        "outputId": "f1487655-37c4-463a-f779-4edad75bb109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0202 13:00:28.505932 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.506758 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.507256 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.507720 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.508349 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.508900 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.509424 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.509933 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.510401 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.510946 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.511501 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.511948 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.512467 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.512938 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.513456 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.513933 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.514425 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.514849 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.515285 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.515736 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.516231 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.516717 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.517161 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.517732 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.518353 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.518876 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.519397 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.520153 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.520665 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.521233 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.523923 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.524324 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.524710 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.525209 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.525833 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.526300 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.526813 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.527258 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.527781 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.528247 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.528733 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.529209 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.529741 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.530272 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.530733 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.531204 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.531683 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.532135 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.532611 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.532992 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.533504 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.533918 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.534377 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.534828 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.535293 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.535742 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.536290 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.536756 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.537256 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.537711 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.538201 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.538620 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.539050 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.539481 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.539964 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.540453 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.540835 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.541293 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.541755 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.542250 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.542716 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.543147 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.543619 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.544045 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.544435 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.544873 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.545328 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.545781 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.546232 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.546710 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.547185 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.547648 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.548101 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.548529 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.548912 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.549337 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.549780 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.550251 138988219970176 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
            "W0202 13:00:28.555230 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.555673 138988219970176 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
            "W0202 13:00:28.556648 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.557481 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.558252 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.559065 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.559822 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.560578 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.561346 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.562105 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.562798 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.563553 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.564263 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.564957 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.565704 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.566435 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.567152 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.567961 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.568688 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.569406 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.570104 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.570803 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.571503 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.572209 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.572870 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.573603 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.574335 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.575037 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.575722 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.576411 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.577137 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.577822 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.578552 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.579293 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.579990 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.580691 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.581390 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.582129 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.582809 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.583577 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.584268 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.584962 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.585670 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.586380 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.587078 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.587770 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.588479 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.589192 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.589890 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.590593 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.591284 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.591955 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.592695 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.593394 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.594133 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.594818 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.595508 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.596239 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.596952 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.597844 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.598569 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.599358 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.600280 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.601398 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.602292 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.603213 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.604135 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.605051 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.605954 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.606866 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.607765 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.608639 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.609551 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.610559 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.611430 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.612362 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.613338 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.614333 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.615293 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.616252 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.617132 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.618104 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.619140 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.620172 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.621155 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.622212 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.623104 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.623942 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
            "W0202 13:00:28.624742 138988219970176 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stage0.rbr_dense.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=2.1255 calibrator=HistogramCalibrator scale=1.0 quant)\n",
            "stage0.rbr_dense.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.3628 calibrator=HistogramCalibrator scale=349.8851318359375 quant)\n",
            "stage0.rbr_1x1.conv.quantizer           : TensorQuantizer(8bit per-tensor amax=2.1255 calibrator=HistogramCalibrator scale=1.0 quant)\n",
            "stage0.rbr_1x1.conv.quantizer_w         : TensorQuantizer(8bit per-tensor amax=0.4948 calibrator=HistogramCalibrator scale=256.5318603515625 quant)\n",
            "stage1.0.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.1008 calibrator=HistogramCalibrator scale=419.8192138671875 quant)\n",
            "stage1.0.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.1891 calibrator=HistogramCalibrator scale=623.5847778320312 quant)\n",
            "stage1.0.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.1008 calibrator=HistogramCalibrator scale=419.8192138671875 quant)\n",
            "stage1.0.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.2498 calibrator=HistogramCalibrator scale=508.22552490234375 quant)\n",
            "stage1.1.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.5491 calibrator=HistogramCalibrator scale=0.001299710595048964 quant)\n",
            "stage1.1.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.1906 calibrator=HistogramCalibrator scale=547.1300659179688 quant)\n",
            "stage1.1.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.5491 calibrator=HistogramCalibrator scale=0.001299710595048964 quant)\n",
            "stage1.1.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.2335 calibrator=HistogramCalibrator scale=543.671875 quant)\n",
            "stage2.0.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.7485 calibrator=HistogramCalibrator scale=0.0009104527998715639 quant)\n",
            "stage2.0.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.1353 calibrator=HistogramCalibrator scale=793.5965576171875 quant)\n",
            "stage2.0.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.7485 calibrator=HistogramCalibrator scale=0.0009104527998715639 quant)\n",
            "stage2.0.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.1574 calibrator=HistogramCalibrator scale=806.3528442382812 quant)\n",
            "stage2.1.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=0.7757 calibrator=HistogramCalibrator scale=0.0019296294776722789 quant)\n",
            "stage2.1.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0746 calibrator=HistogramCalibrator scale=1353.4476318359375 quant)\n",
            "stage2.1.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=0.7757 calibrator=HistogramCalibrator scale=0.0019296294776722789 quant)\n",
            "stage2.1.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0735 calibrator=HistogramCalibrator scale=1728.2066650390625 quant)\n",
            "stage2.2.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.2121 calibrator=HistogramCalibrator scale=0.00111574016045779 quant)\n",
            "stage2.2.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0845 calibrator=HistogramCalibrator scale=1104.7998046875 quant)\n",
            "stage2.2.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.2121 calibrator=HistogramCalibrator scale=0.00111574016045779 quant)\n",
            "stage2.2.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0931 calibrator=HistogramCalibrator scale=1364.03125 quant)\n",
            "stage2.3.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.4875 calibrator=HistogramCalibrator scale=0.0005209675873629749 quant)\n",
            "stage2.3.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0994 calibrator=HistogramCalibrator scale=903.7467041015625 quant)\n",
            "stage2.3.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.4875 calibrator=HistogramCalibrator scale=0.0005209675873629749 quant)\n",
            "stage2.3.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.1354 calibrator=HistogramCalibrator scale=937.5003051757812 quant)\n",
            "stage3.0.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.6484 calibrator=HistogramCalibrator scale=0.0003970199031755328 quant)\n",
            "stage3.0.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.1005 calibrator=HistogramCalibrator scale=740.3419799804688 quant)\n",
            "stage3.0.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.6484 calibrator=HistogramCalibrator scale=0.0003970199031755328 quant)\n",
            "stage3.0.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0875 calibrator=HistogramCalibrator scale=1036.6353759765625 quant)\n",
            "stage3.1.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=0.6895 calibrator=HistogramCalibrator scale=0.000951406720560044 quant)\n",
            "stage3.1.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0481 calibrator=HistogramCalibrator scale=1755.15380859375 quant)\n",
            "stage3.1.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=0.6895 calibrator=HistogramCalibrator scale=0.000951406720560044 quant)\n",
            "stage3.1.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0500 calibrator=HistogramCalibrator scale=2334.70654296875 quant)\n",
            "stage3.2.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=0.9848 calibrator=HistogramCalibrator scale=0.00045488475007005036 quant)\n",
            "stage3.2.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0503 calibrator=HistogramCalibrator scale=1733.7703857421875 quant)\n",
            "stage3.2.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=0.9848 calibrator=HistogramCalibrator scale=0.00045488475007005036 quant)\n",
            "stage3.2.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0478 calibrator=HistogramCalibrator scale=2062.927734375 quant)\n",
            "stage3.3.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.2430 calibrator=HistogramCalibrator scale=0.0007393453852273524 quant)\n",
            "stage3.3.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1473.2110595703125 quant)\n",
            "stage3.3.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.2430 calibrator=HistogramCalibrator scale=0.0007393453852273524 quant)\n",
            "stage3.3.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0419 calibrator=HistogramCalibrator scale=2603.29345703125 quant)\n",
            "stage3.4.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.2946 calibrator=HistogramCalibrator scale=0.0004984228871762753 quant)\n",
            "stage3.4.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0610 calibrator=HistogramCalibrator scale=1127.9583740234375 quant)\n",
            "stage3.4.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.2946 calibrator=HistogramCalibrator scale=0.0004984228871762753 quant)\n",
            "stage3.4.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0491 calibrator=HistogramCalibrator scale=2113.308349609375 quant)\n",
            "stage3.5.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.3737 calibrator=HistogramCalibrator scale=0.0005940690753050148 quant)\n",
            "stage3.5.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0622 calibrator=HistogramCalibrator scale=1322.8944091796875 quant)\n",
            "stage3.5.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.3737 calibrator=HistogramCalibrator scale=0.0005940690753050148 quant)\n",
            "stage3.5.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0474 calibrator=HistogramCalibrator scale=2299.19873046875 quant)\n",
            "stage3.6.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.3062 calibrator=HistogramCalibrator scale=0.0007017696625553071 quant)\n",
            "stage3.6.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0542 calibrator=HistogramCalibrator scale=1451.494140625 quant)\n",
            "stage3.6.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.3062 calibrator=HistogramCalibrator scale=0.0007017696625553071 quant)\n",
            "stage3.6.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0357 calibrator=HistogramCalibrator scale=3030.50634765625 quant)\n",
            "stage3.7.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.3802 calibrator=HistogramCalibrator scale=0.00033015524968504906 quant)\n",
            "stage3.7.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0540 calibrator=HistogramCalibrator scale=1474.31591796875 quant)\n",
            "stage3.7.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.3802 calibrator=HistogramCalibrator scale=0.00033015524968504906 quant)\n",
            "stage3.7.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0291 calibrator=HistogramCalibrator scale=3242.998046875 quant)\n",
            "stage3.8.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.4555 calibrator=HistogramCalibrator scale=0.00046310710604302585 quant)\n",
            "stage3.8.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0540 calibrator=HistogramCalibrator scale=1615.5277099609375 quant)\n",
            "stage3.8.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.4555 calibrator=HistogramCalibrator scale=0.00046310710604302585 quant)\n",
            "stage3.8.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0266 calibrator=HistogramCalibrator scale=3954.505615234375 quant)\n",
            "stage3.9.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.5523 calibrator=HistogramCalibrator scale=0.0003686116251628846 quant)\n",
            "stage3.9.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0534 calibrator=HistogramCalibrator scale=1125.8734130859375 quant)\n",
            "stage3.9.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.5523 calibrator=HistogramCalibrator scale=0.0003686116251628846 quant)\n",
            "stage3.9.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0524 calibrator=HistogramCalibrator scale=1659.3878173828125 quant)\n",
            "stage3.10.rbr_dense.conv.quantizer      : TensorQuantizer(8bit per-tensor amax=1.5608 calibrator=HistogramCalibrator scale=0.0008287421660497785 quant)\n",
            "stage3.10.rbr_dense.conv.quantizer_w    : TensorQuantizer(8bit per-tensor amax=0.0418 calibrator=HistogramCalibrator scale=1839.17333984375 quant)\n",
            "stage3.10.rbr_1x1.conv.quantizer        : TensorQuantizer(8bit per-tensor amax=1.5608 calibrator=HistogramCalibrator scale=0.0008287421660497785 quant)\n",
            "stage3.10.rbr_1x1.conv.quantizer_w      : TensorQuantizer(8bit per-tensor amax=0.0228 calibrator=HistogramCalibrator scale=4612.30712890625 quant)\n",
            "stage3.11.rbr_dense.conv.quantizer      : TensorQuantizer(8bit per-tensor amax=1.5380 calibrator=HistogramCalibrator scale=0.00047514057951048017 quant)\n",
            "stage3.11.rbr_dense.conv.quantizer_w    : TensorQuantizer(8bit per-tensor amax=0.0397 calibrator=HistogramCalibrator scale=1487.13720703125 quant)\n",
            "stage3.11.rbr_1x1.conv.quantizer        : TensorQuantizer(8bit per-tensor amax=1.5380 calibrator=HistogramCalibrator scale=0.00047514057951048017 quant)\n",
            "stage3.11.rbr_1x1.conv.quantizer_w      : TensorQuantizer(8bit per-tensor amax=0.0241 calibrator=HistogramCalibrator scale=4610.83935546875 quant)\n",
            "stage3.12.rbr_dense.conv.quantizer      : TensorQuantizer(8bit per-tensor amax=1.4459 calibrator=HistogramCalibrator scale=0.0006209207931533456 quant)\n",
            "stage3.12.rbr_dense.conv.quantizer_w    : TensorQuantizer(8bit per-tensor amax=0.0377 calibrator=HistogramCalibrator scale=2066.015869140625 quant)\n",
            "stage3.12.rbr_1x1.conv.quantizer        : TensorQuantizer(8bit per-tensor amax=1.4459 calibrator=HistogramCalibrator scale=0.0006209207931533456 quant)\n",
            "stage3.12.rbr_1x1.conv.quantizer_w      : TensorQuantizer(8bit per-tensor amax=0.0213 calibrator=HistogramCalibrator scale=3852.668701171875 quant)\n",
            "stage3.13.rbr_dense.conv.quantizer      : TensorQuantizer(8bit per-tensor amax=1.1398 calibrator=HistogramCalibrator scale=0.004640910774469376 quant)\n",
            "stage3.13.rbr_dense.conv.quantizer_w    : TensorQuantizer(8bit per-tensor amax=0.0353 calibrator=HistogramCalibrator scale=2128.9443359375 quant)\n",
            "stage3.13.rbr_1x1.conv.quantizer        : TensorQuantizer(8bit per-tensor amax=1.1398 calibrator=HistogramCalibrator scale=0.004640910774469376 quant)\n",
            "stage3.13.rbr_1x1.conv.quantizer_w      : TensorQuantizer(8bit per-tensor amax=0.0216 calibrator=HistogramCalibrator scale=5691.36474609375 quant)\n",
            "stage4.0.rbr_dense.conv.quantizer       : TensorQuantizer(8bit per-tensor amax=1.2039 calibrator=HistogramCalibrator scale=0.0025944889057427645 quant)\n",
            "stage4.0.rbr_dense.conv.quantizer_w     : TensorQuantizer(8bit per-tensor amax=0.0085 calibrator=HistogramCalibrator scale=9720.8115234375 quant)\n",
            "stage4.0.rbr_1x1.conv.quantizer         : TensorQuantizer(8bit per-tensor amax=1.2039 calibrator=HistogramCalibrator scale=0.0025944889057427645 quant)\n",
            "stage4.0.rbr_1x1.conv.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0174 calibrator=HistogramCalibrator scale=5896.40283203125 quant)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    stats = collect_stats(model, calib_data, num_batches=2, device=device)\n",
        "    amax = compute_amax(model, method=\"percentile\", percentile=99.99, device=device)\n",
        "\n",
        "    # optional - test different calibration methods\n",
        "    #amax = compute_amax(model, method=\"mse\")\n",
        "    #amax = compute_amax(model, method=\"entropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a48a6e",
      "metadata": {
        "id": "57a48a6e"
      },
      "source": [
        "## Run model evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c927c698",
      "metadata": {
        "id": "c927c698",
        "outputId": "068d1ce2-5be4-4e47-8933-88c4ef8b184e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Power of approximated operations:  94.43 %\n",
            "Model compiled. Running evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:20<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.900561805999985\n",
            "Accuracy of the network on the 10000 test images: 91.7167 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# set desired approximate multiplier in each layer\n",
        "\n",
        "#at first, set all layers to have the 8-bit accurate multiplier\n",
        "axx_list = [{'axx_mult' : 'mul8s_acc', 'axx_power' : 1.0, 'quant_bits' : 8, 'fake_quant' : False}]*len(conv2d_layers)\n",
        "\n",
        "# For example, set the first 10 layers to be approximated with a specific multiplier\n",
        "axx_list[0:10] = [{'axx_mult' : 'mul8s_1L2H', 'axx_power' : 0.7082, 'quant_bits' : 8, 'fake_quant' : False}] * 10\n",
        "\n",
        "returned_power = [0]\n",
        "replace_conv_layers(model,  AdaptConv2D, axx_list, total_macs, total_params, layer_count=[0], returned_power = returned_power, initialize = False)\n",
        "print('Power of approximated operations: ', round(returned_power[0], 2), '%')\n",
        "print('Model compiled. Running evaluation')\n",
        "\n",
        "# Run evaluation on the validation dataset\n",
        "top1 = evaluate_cifar10(model, val_data, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c139533e-bab5-4144-9bf3-ad2497f7d839",
      "metadata": {
        "id": "c139533e-bab5-4144-9bf3-ad2497f7d839"
      },
      "source": [
        "## Run model retraining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "182ef59c-c29c-4bf6-afc4-1b4fb1e6bc89",
      "metadata": {
        "id": "182ef59c-c29c-4bf6-afc4-1b4fb1e6bc89",
        "outputId": "7a9cc9ce-4328-4128-adbb-2924f1777a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/39]  eta: 0:00:40  lr: 0.0001  img/s: 151.10814288754062  loss: 0.0849 (0.0849)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 1.0469  data: 0.1998  max mem: 748\n",
            "Epoch: [0]  [10/39]  eta: 0:00:10  lr: 0.0001  img/s: 423.8262731265848  loss: 0.0978 (0.0935)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (99.8580)  time: 0.3711  data: 0.0185  max mem: 781\n",
            "Epoch: [0]  [20/39]  eta: 0:00:06  lr: 0.0001  img/s: 423.4575474414096  loss: 0.0825 (0.0863)  acc1: 96.8750 (97.1726)  acc5: 100.0000 (99.8140)  time: 0.3035  data: 0.0003  max mem: 781\n",
            "Epoch: [0]  [30/39]  eta: 0:00:02  lr: 0.0001  img/s: 419.30198876594045  loss: 0.0814 (0.0869)  acc1: 97.6562 (97.2530)  acc5: 100.0000 (99.7732)  time: 0.3036  data: 0.0002  max mem: 781\n",
            "Epoch: [0] Total time: 0:00:12\n"
          ]
        }
      ],
      "source": [
        "from classification.train import train_one_epoch\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001) # set desired learning rate\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "#one epoch retrain\n",
        "train_one_epoch(model, criterion, optimizer, calib_data, device, 0, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d65da4f4-d0a9-4fe5-a70d-935ccb238c4a",
      "metadata": {
        "id": "d65da4f4-d0a9-4fe5-a70d-935ccb238c4a"
      },
      "source": [
        "## Re-run model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f6e1dd-07bb-4795-b0d6-34d7680f11c7",
      "metadata": {
        "id": "e9f6e1dd-07bb-4795-b0d6-34d7680f11c7",
        "outputId": "e430fe28-9087-4002-ede1-a0119b60cf33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:20<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.946440060999976\n",
            "Accuracy of the network on the 10000 test images: 91.9671 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "top1 = evaluate_cifar10(model, val_data, device = device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}